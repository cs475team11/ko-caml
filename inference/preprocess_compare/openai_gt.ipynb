{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get openai api key from openai_config.json file\n",
    "import json\n",
    "with open('../openai_config.json') as f:\n",
    "    openai_api_key = json.load(f)['openai_api_key']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "%env OPENAI_API_KEY = {openai_api_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm just a computer program, so I don't have feelings, but I'm here to help you. How can I assist you today?\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o\")\n",
    "llm.invoke(\"Hello, how are you?\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'품목명: 아이시스 8.0 생수, 200ml, 40개'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from langchain.document_loaders import CSVLoader\n",
    "# input_loader_kor = CSVLoader(r\"../../guidance_for_environmental_impact_factor_mapping_on_aws/assets/input/coupang_product_names_groceries_v3_kor.csv\", encoding='utf-8-sig')\n",
    "# input_doc_kor = input_loader_kor.load()\n",
    "\n",
    "# input_doc_kor[100].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PRODUCT_NAME: Weikfield Spaghetti Pasta, 400g'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.document_loaders import CSVLoader\n",
    "input_loader_eng = CSVLoader(r\"../../guidance_for_environmental_impact_factor_mapping_on_aws/assets/input/sample_amazon_product_names_groceries_eng.csv\", encoding='utf-8-sig')\n",
    "input_doc_eng = input_loader_eng.load()\n",
    "\n",
    "input_doc_eng[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "prompt = \"\"\"You are a Lifecycle Analysis expert matching grocery products to their Harmonized System (HS) Codes.\n",
    "\n",
    "I want to do of LCA of grocery products based on Environmentally Extended Input Output (EEIO) Environmental Impact Factors (EIF). I am interested in the environmental impact associated with the materials and manufacturing phase of the product. I am given a grocery product and three possible corresponding HS codes and descriptions. \n",
    "\n",
    "I want to pick the HS code and description that best match the given product. Include justification for your choice.\n",
    "Format the output in JSON with the keys BestHSCode, BestHSDescription, Justification.\n",
    "\n",
    "Product:\n",
    "{product_name}\n",
    "\n",
    "What HS Code is the best match for the provided product? \n",
    "\n",
    "Make the most of the given information. DO NOT say that information is limited or ask for more information.\n",
    "YOU MUST choose a best code and title. YOU MUST include a justification for your choice.\n",
    "Avoid filler words such as \"Based on the details\" or \"happy to assist\", keep your response to the point.\n",
    "Do not repeat the given instructions or information. \n",
    "DO NOT say you have insufficient information for an LCA.\n",
    "\n",
    "Respond with the JSON output and nothing else.\"\"\"\n",
    "prompt = PromptTemplate.from_template(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results: {'BestHSCode': '190219', 'BestHSDescription': 'Pasta,whetherornotcookedorstuffed(withmeatorothersubstances)orotherwiseprepared,otherthanuncookedpasta,notstuffedorotherwiseprepared', 'Justification': 'WeikfieldSpaghettiPastaisanuncookedpastaproduct,whichalignswiththedescriptionofHScode190219,coveringpastaproductsthatarenotcooked,stuffed,orotherwiseprepared.', 'PRODUCT_NAME': 'PRODUCT_NAME: Weikfield Spaghetti Pasta, 400g', 'Ground Truth': '190219'}\n"
     ]
    }
   ],
   "source": [
    "# Initialize results storage\n",
    "results_eng = []\n",
    "\n",
    "# Process each row using the graph\n",
    "for doc in input_doc_eng:\n",
    "    # # Extract CommodityDescription from the page_content using regex\n",
    "    # match = re.search(r\"CommodityDescription: (.+)\", doc.page_content)\n",
    "    # activity = match.group(1).strip() if match else None  # Extract the description\n",
    "\n",
    "    activity = doc.page_content # Extract the Product Name\n",
    "\n",
    "    if activity:\n",
    "        msg = prompt.invoke({\"product_name\": activity})\n",
    "        result = json.loads(llm.invoke(msg).content.strip(\"```\").lstrip(\"json\").replace(\"\\n\", \"\").replace(\" \", \"\"))\n",
    "        result['PRODUCT_NAME'] = activity\n",
    "        result[\"Ground Truth\"] = result.get(\"BestHSCode\").replace(\".\", \"\").rjust(6, \"0\")\n",
    "        \n",
    "        # Extract context and answer from the state after processing\n",
    "        results_eng.append(result)\n",
    "\n",
    "# Print the results for debugging\n",
    "print(\"Final results:\", results_eng[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "to_csv = results_eng\n",
    "keys = to_csv[0].keys()\n",
    "\n",
    "with open(\"sample_amazon_gt\", 'w', newline='') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(to_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"sample_amazon_gt\")\n",
    "df.drop(columns=[\"BestHSCode\", \"BestHSDescription\", \"Justification\"], inplace=True)\n",
    "df.to_csv(\"sample_amazon_gt_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kocaml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
